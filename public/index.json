


[{"content":"","date":"3 January 2026","externalUrl":null,"permalink":"/tags/ai-locale/","section":"Tags","summary":"","title":"AI Locale","type":"tags"},{"content":" Il Contesto # Nel mio percorso di specializzazione come IT Administrator verso ruoli MLOps, ho deciso di costruire un\u0026rsquo;infrastruttura locale per gestire l\u0026rsquo;intero ciclo di vita di un\u0026rsquo;applicazione basata su Intelligenza Artificiale. L\u0026rsquo;obiettivo era passare dalla teoria alla pratica, orchestrando container e modelli LLM in un ambiente controllato ma scalabile, sfruttando le mie basi solide (CompTIA A+, ITF+, Azure Fundamentals).\nL\u0026rsquo;Architettura # Il progetto Polana AI non è solo un\u0026rsquo;installazione software, è un\u0026rsquo;architettura completa costruita su hardware commodity.\nHardware: Mini PC Intel Core i7 con 16GB di RAM. OS: Ubuntu Server (headless) per massimizzare le risorse. Orchestrazione: K3s (Lightweight Kubernetes) per una gestione efficiente e certificata dei container. AI Engine \u0026amp; UI: Ollama per il serving del modello e Open WebUI per l\u0026rsquo;interfaccia utente. Modello AI: Google Gemma 3 4B (il nuovo standard del 2026 per efficienza). Networking: Cloudflare Zero Trust Tunnel per l\u0026rsquo;accesso sicuro dall\u0026rsquo;esterno senza esporre porte sul router. La Cronistoria del Build (3 Gennaio 2026) # 1. L\u0026rsquo;Installazione \u0026ldquo;Bare Metal\u0026rdquo; (Mattina) # La giornata è iniziata con un\u0026rsquo;installazione pulita di Ubuntu Server tramite chiavetta USB, preparando il \u0026ldquo;ferro\u0026rdquo; per il suo nuovo ruolo.\n2. La Transizione verso l\u0026rsquo;Orchestrazione # Ho inizialmente testato il deploy tramite Docker classico. Tuttavia, per allinearmi alle best practice MLOps, ho deciso di migrare rapidamente a Kubernetes (K3s).\nSfida Tecnica: Durante la migrazione, si è creato un conflitto di porte tra i vecchi processi Docker e i nuovi Pod Kubernetes. Risoluzione: Ho eseguito un audit dei processi con ps aux e docker ps, terminato i vecchi container e pulito il sistema con docker system prune e ncdu per recuperare spazio su disco, lasciando il campo libero a K3s. 3. Deploy e Configurazione (Sera) # Una volta stabilizzato il cluster K3s:\nHo eseguito il pull del modello Gemma 3 4B direttamente nel volume persistente del pod Ollama con kubectl exec. Ho configurato il servizio Open WebUI come NodePort per l\u0026rsquo;accesso LAN. Ho riconfigurato il Cloudflare Tunnel per puntare al Service ClusterIP interno di Kubernetes (http://open-webui:80), rendendo l\u0026rsquo;applicazione accessibile globalmente e in sicurezza su ai.polanatech.com. Risultati e Prossimi Passi # In meno di 24 ore, sono passato da un Mini PC spento a un\u0026rsquo;infrastruttura MLOps funzionante che ospita un LLM all\u0026rsquo;avanguardia, gestita come codice (Infrastructure as Code).\nI prossimi step per Polana AI includono:\nAutomatizzare l\u0026rsquo;aggiornamento dei modelli tramite pipeline CI/CD. Implementare il monitoraggio delle risorse del cluster con Prometheus e Grafana. Esplorare tecniche di fine-tuning locale sui miei dati. ","date":"3 January 2026","externalUrl":null,"permalink":"/posts/polana-ai-build/","section":"Posts","summary":"Il Contesto # Nel mio percorso di specializzazione come IT Administrator verso ruoli MLOps, ho deciso di costruire un’infrastruttura locale per gestire l’intero ciclo di vita di un’applicazione basata su Intelligenza Artificiale. L’obiettivo era passare dalla teoria alla pratica, orchestrando container e modelli LLM in un ambiente controllato ma scalabile, sfruttando le mie basi solide (CompTIA A+, ITF+, Azure Fundamentals).\n","title":"Building Polana AI: Da Zero a MLOps Locale con Kubernetes e Gemma 3","type":"posts"},{"content":"","date":"3 January 2026","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","date":"3 January 2026","externalUrl":null,"permalink":"/tags/gemma-3/","section":"Tags","summary":"","title":"Gemma 3","type":"tags"},{"content":"","date":"3 January 2026","externalUrl":null,"permalink":"/tags/homelab/","section":"Tags","summary":"","title":"HomeLab","type":"tags"},{"content":"","date":"3 January 2026","externalUrl":null,"permalink":"/categories/infrastruttura/","section":"Categories","summary":"","title":"Infrastruttura","type":"categories"},{"content":"","date":"3 January 2026","externalUrl":null,"permalink":"/tags/k3s/","section":"Tags","summary":"","title":"K3s","type":"tags"},{"content":"","date":"3 January 2026","externalUrl":null,"permalink":"/tags/kubernetes/","section":"Tags","summary":"","title":"Kubernetes","type":"tags"},{"content":"","date":"3 January 2026","externalUrl":null,"permalink":"/tags/linux/","section":"Tags","summary":"","title":"Linux","type":"tags"},{"content":"","date":"3 January 2026","externalUrl":null,"permalink":"/tags/mlops/","section":"Tags","summary":"","title":"MLOps","type":"tags"},{"content":"","date":"3 January 2026","externalUrl":null,"permalink":"/","section":"PolanaTech","summary":"","title":"PolanaTech","type":"page"},{"content":"","date":"3 January 2026","externalUrl":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":"","date":"3 January 2026","externalUrl":null,"permalink":"/categories/progetti/","section":"Categories","summary":"","title":"Progetti","type":"categories"},{"content":"","date":"3 January 2026","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"}]