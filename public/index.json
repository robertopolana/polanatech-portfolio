


[{"content":"","date":"3 January 2026","externalUrl":null,"permalink":"/it/tags/ai-locale/","section":"Tags","summary":"","title":"AI Locale","type":"tags"},{"content":" The Context # On my path as an IT Specialist specializing toward MLOps roles, I decided to build a local infrastructure to manage the entire lifecycle of an AI-based application. The goal was to move from theory to practice, orchestrating containers and LLM models in a controlled yet scalable environment.\nThe Architecture # The Polana AI project is more than just a software installation; it is a full-stack architecture built on commodity hardware.\nHardware: Intel Core i7 Mini PC with 16GB RAM. OS: Ubuntu Server (headless) to maximize resource allocation. Orchestration: K3s (Lightweight Kubernetes) for efficient and certified container management. AI Engine \u0026amp; UI: Ollama for model serving and Open WebUI for the user interface. AI Model: Google Gemma 3 4B (the 2026 standard for efficiency). Networking: Cloudflare Zero Trust Tunnel for secure external access without port forwarding. Build Timeline (January 3, 2026) # 1. Bare Metal Installation # The process began with a clean install of Ubuntu Server via USB, preparing the hardware for its new role as an AI node.\n2. Transitioning to Orchestration # I initially tested the deployment using standard Docker. However, to align with MLOps best practices, I quickly migrated to Kubernetes (K3s).\nTechnical Challenge: During the migration, a port conflict occurred between legacy Docker processes and the new Kubernetes Pods. Resolution: I performed a process audit using ps aux and docker ps, terminated old containers, and cleaned the system with docker system prune and ncdu to reclaim disk space, clearing the path for K3s. 3. Deployment and Configuration # Once the K3s cluster was stabilized:\nI pulled the Gemma 3 4B model directly into the Ollama pod\u0026rsquo;s persistent volume using kubectl exec. Configured the Open WebUI service as a NodePort for LAN access. Reconfigured the Cloudflare Tunnel to point to the internal Kubernetes ClusterIP Service (http://open-webui:80), making the app securely accessible globally at ai.polanatech.com. Results and Next Steps # I successfully transitioned from an idle Mini PC to a functional MLOps infrastructure hosting a cutting-edge LLM, managed as Infrastructure as Code (IaC).\nFuture steps for Polana AI include:\nAutomating model updates via CI/CD pipelines. Implementing cluster resource monitoring with Prometheus and Grafana. Exploring local fine-tuning techniques on proprietary data. ","date":"3 January 2026","externalUrl":null,"permalink":"/posts/polana-ai-build/","section":"Posts","summary":"The Context # On my path as an IT Specialist specializing toward MLOps roles, I decided to build a local infrastructure to manage the entire lifecycle of an AI-based application. The goal was to move from theory to practice, orchestrating containers and LLM models in a controlled yet scalable environment.\n","title":"Building Polana AI: From Zero to Local MLOps with Kubernetes and Gemma 3","type":"posts"},{"content":"","date":"3 January 2026","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","date":"3 January 2026","externalUrl":null,"permalink":"/tags/gemma-3/","section":"Tags","summary":"","title":"Gemma 3","type":"tags"},{"content":"","date":"3 January 2026","externalUrl":null,"permalink":"/tags/homelab/","section":"Tags","summary":"","title":"HomeLab","type":"tags"},{"content":"","date":"3 January 2026","externalUrl":null,"permalink":"/categories/infrastructure/","section":"Categories","summary":"","title":"Infrastructure","type":"categories"},{"content":"","date":"3 January 2026","externalUrl":null,"permalink":"/it/categories/infrastruttura/","section":"Categories","summary":"","title":"Infrastruttura","type":"categories"},{"content":"","date":"3 January 2026","externalUrl":null,"permalink":"/tags/k3s/","section":"Tags","summary":"","title":"K3s","type":"tags"},{"content":"","date":"3 January 2026","externalUrl":null,"permalink":"/tags/kubernetes/","section":"Tags","summary":"","title":"Kubernetes","type":"tags"},{"content":"","date":"3 January 2026","externalUrl":null,"permalink":"/tags/linux/","section":"Tags","summary":"","title":"Linux","type":"tags"},{"content":"","date":"3 January 2026","externalUrl":null,"permalink":"/tags/local-ai/","section":"Tags","summary":"","title":"Local AI","type":"tags"},{"content":"","date":"3 January 2026","externalUrl":null,"permalink":"/tags/mlops/","section":"Tags","summary":"","title":"MLOps","type":"tags"},{"content":"","date":"3 January 2026","externalUrl":null,"permalink":"/","section":"PolanaTech","summary":"","title":"PolanaTech","type":"page"},{"content":"","date":"3 January 2026","externalUrl":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":"","date":"3 January 2026","externalUrl":null,"permalink":"/it/categories/progetti/","section":"Categories","summary":"","title":"Progetti","type":"categories"},{"content":"","date":"3 January 2026","externalUrl":null,"permalink":"/categories/projects/","section":"Categories","summary":"","title":"Projects","type":"categories"},{"content":"","date":"3 January 2026","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"}]